{
 "metadata": {
  "name": "",
  "signature": "sha256:1664467f69348c9203c09679c01e81ab5ebaab7141b2476b2822b903be5219fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shared_dataset(data_xy):\n",
      "    \"\"\" Function that loads the dataset into shared variables\n",
      "\n",
      "    The reason we store our dataset in shared variables is to allow\n",
      "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
      "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
      "    is needed (the default behaviour if the data is not in a shared\n",
      "    variable) would lead to a large decrease in performance.\n",
      "    \"\"\"\n",
      "    data_x, data_y = data_xy\n",
      "    shared_x = theano.shared(numpy.asarray(data_x, dtype=theano.config.floatX))\n",
      "    shared_y = theano.shared(numpy.asarray(data_y, dtype=theano.config.floatX))\n",
      "    # When storing data on the GPU it has to be stored as floats\n",
      "    # therefore we will store the labels as ``floatX`` as well\n",
      "    # (``shared_y`` does exactly that). But during our computations\n",
      "    # we need them as ints (we use labels as index, and if they are\n",
      "    # floats it doesn't make sense) therefore instead of returning\n",
      "    # ``shared_y`` we will have to cast it to int. This little hack\n",
      "    # lets us get around this issue\n",
      "    return shared_x, T.cast(shared_y, 'int32')\n",
      "\n",
      "test_set_x, test_set_y = shared_dataset(test_set)\n",
      "valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
      "train_set_x, train_set_y = shared_dataset(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import cPickle, gzip, numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from keras.utils import np_utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "train_set, valid_set, test_set = cPickle.load(f)\n",
      "f.close()\n",
      "\n",
      "train_set_x = train_set[0]\n",
      "train_set_y = np_utils.to_categorical(train_set[1], 10)\n",
      "\n",
      "test_set_x = test_set[0]\n",
      "test_set_y = np_utils.to_categorical(test_set[1], 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_set_x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 784)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure()\n",
      "plt.imshow(train_set[0][2].reshape((28,28)))\n",
      "print \"Actual: \", train_set[1][2]\n",
      "print \"ArgMax: \", numpy.argmax(train_set_y[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Actual:  4\n",
        "ArgMax:  4\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1f139d0>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_set_error(model, n=10000):\n",
      "    out = model.predict_proba(test_set_x[:n])\n",
      "\n",
      "    correct = 0\n",
      "    for i in numpy.arange(n):\n",
      "        if numpy.argmax(out[i]) == numpy.argmax(test_set_y[i]): correct += 1\n",
      "        #print numpy.argmax(out[i]), numpy.argmax(test_set_y[i])\n",
      "\n",
      "    return 100.0 - correct/10000.0*100.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_set[0][0].shape\n",
      "print type(test_set_x) == T.sharedvar.TensorSharedVariable\n",
      "print type(train_set) == T.sharedvar.TensorSharedVariable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(784,)\n",
        "False\n",
        "False\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Good Baseline"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Network: 784 -> 64 -> 64 ->10\n",
      "* Activations: ReLU -> ReLU -> Softmax\n",
      "* Dropout: 10% -> 90% -> 0%\n",
      "* HyperParameters:\n",
      "    - Learning Rate: .1\n",
      "    - Weight Decay: .000001\n",
      "    - Momentum: .5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(Activation('relu'))\n",
      "model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(Activation('relu'))\n",
      "model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Stacked Linear Layers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Network: 784 -> 64 -> 64 ->10\n",
      "* Activations: Linear -> Linear -> Softmax\n",
      "* Dropout: 0% -> 0% -> 0%\n",
      "* HyperParameters:\n",
      "    - Learning Rate: .1\n",
      "    - Weight Decay: .000001\n",
      "    - Momentum: .5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(Activation('linear'))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(Activation('linear'))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.79\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Single Linear Layer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Network: 784 -> 64 ->10\n",
      "* Activations: Linear -> Softmax\n",
      "* Dropout: 0% -> 0%\n",
      "* HyperParameters:\n",
      "    - Learning Rate: .1\n",
      "    - Weight Decay: .000001\n",
      "    - Momentum: .5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(Activation('linear'))\n",
      "#model.add(Dropout(0.1))\n",
      "#model.add(Dense(64, 64, init='uniform'))\n",
      "#model.add(Activation('linear'))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.59\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Activation Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Network: 784 -> 64 -> 64 ->10\n",
      "* Dropout: 0% -> 0% -> 0%\n",
      "* HyperParameters:\n",
      "    - Learning Rate: .1\n",
      "    - Weight Decay: .000001\n",
      "    - Momentum: .5"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sigmoid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(Activation('sigmoid'))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(Activation('sigmoid'))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.64\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hyperbolic Tangent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(Activation('tanh'))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(Activation('tanh'))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.52\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "LReLU"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import LeakyReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(LeakyReLU(alpha=.001))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(LeakyReLU(alpha=.001))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.58\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "PReLU"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.48\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hidden Units"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Double"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 128, init='uniform'))\n",
      "model.add(PReLU(input_shape=(128,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(128, 128, init='uniform'))\n",
      "model.add(PReLU(input_shape=(128,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(128, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.22\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Half"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 32, init='uniform'))\n",
      "model.add(PReLU(input_shape=(32,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(32, 32, init='uniform'))\n",
      "model.add(PReLU(input_shape=(32,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(32, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.43\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hidden Layers"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "One Less"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "#model.add(Dense(64, 64, init='uniform'))\n",
      "#model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.61\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "One More"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.02\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hyperparameters"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Learning Rate"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Smaller"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.58\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Larger"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.2, decay=1e-6, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.56\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Weight Decay"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Smaller"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-7, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.92\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Larger"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-5, momentum=0.5, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "90.42\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Momentum"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Smaller"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.25, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.74\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Larger"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout\n",
      "from keras.layers.advanced_activations import PReLU\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(784, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.1))\n",
      "model.add(Dense(64, 64, init='uniform'))\n",
      "model.add(PReLU(input_shape=(64,)))\n",
      "#model.add(Dropout(0.9))\n",
      "model.add(Dense(64, 10, init='uniform'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(train_set_x, train_set_y, nb_epoch=125, batch_size=600, verbose=False)\n",
      "\n",
      "print test_set_error(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.47\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Convolutional NN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Baseline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "train_set, valid_set, test_set = cPickle.load(f)\n",
      "f.close()\n",
      "\n",
      "train_set_x = train_set[0].reshape((50000, 1, 28, 28))\n",
      "train_set_y = np_utils.to_categorical(train_set[1], 10)\n",
      "\n",
      "test_set_x = test_set[0].reshape((10000, 1, 28, 28))\n",
      "test_set_y = np_utils.to_categorical(test_set[1], 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_set_x.shape\n",
      "print test_set_x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 1, 28, 28)\n",
        "(10000, 1, 28, 28)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
      "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
      "from keras.optimizers import SGD\n",
      "from keras.models import Sequential\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Convolution2D(28, 1, 3, 3, border_mode='full')) \n",
      "model.add(Activation('relu'))\n",
      "model.add(Convolution2D(28, 28, 3, 3))\n",
      "model.add(Activation('relu'))\n",
      "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
      "model.add(Dropout(0.25))\n",
      "\n",
      "model.add(Convolution2D(56, 28, 3, 3, border_mode='full')) \n",
      "model.add(Activation('relu'))\n",
      "model.add(Convolution2D(56, 56, 3, 3)) \n",
      "model.add(Activation('relu'))\n",
      "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
      "model.add(Dropout(0.25))\n",
      "\n",
      "model.add(Flatten(56*7*7))\n",
      "model.add(Dense(56*7*7, 56, init='normal'))\n",
      "model.add(Activation('relu'))\n",
      "model.add(Dropout(0.5))\n",
      "\n",
      "model.add(Dense(56, 10, init='normal'))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(train_set_x[:640*10], train_set_y[:640*10], nb_epoch=1, batch_size=64, verbose=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 0\n",
        "\b"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "64/6400 [..............................] - ETA: 267s - loss: 2.3055"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b128/6400 [..............................] - ETA: 296s - loss: 2.3027"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b192/6400 [..............................] - ETA: 306s - loss: 2.3031"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b256/6400 [>.............................] - ETA: 309s - loss: 2.3029"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b320/6400 [>.............................] - ETA: 310s - loss: 2.3036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b384/6400 [>.............................] - ETA: 309s - loss: 2.3032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b448/6400 [=>............................] - ETA: 308s - loss: 2.3024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b512/6400 [=>............................] - ETA: 306s - loss: 2.3021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b576/6400 [=>............................] - ETA: 304s - loss: 2.3020"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b640/6400 [==>...........................] - ETA: 301s - loss: 2.3020"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b704/6400 [==>...........................] - ETA: 299s - loss: 2.3018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b768/6400 [==>...........................] - ETA: 296s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b832/6400 [==>...........................] - ETA: 293s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b896/6400 [===>..........................] - ETA: 290s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b960/6400 [===>..........................] - ETA: 287s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1024/6400 [===>..........................] - ETA: 284s - loss: 2.3008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1088/6400 [====>.........................] - ETA: 280s - loss: 2.3011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1152/6400 [====>.........................] - ETA: 277s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1216/6400 [====>.........................] - ETA: 274s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1280/6400 [=====>........................] - ETA: 271s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1344/6400 [=====>........................] - ETA: 268s - loss: 2.3015"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1408/6400 [=====>........................] - ETA: 264s - loss: 2.3016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1472/6400 [=====>........................] - ETA: 261s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1536/6400 [======>.......................] - ETA: 258s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1600/6400 [======>.......................] - ETA: 255s - loss: 2.3015"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1664/6400 [======>.......................] - ETA: 251s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1728/6400 [=======>......................] - ETA: 248s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1792/6400 [=======>......................] - ETA: 245s - loss: 2.3015"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1856/6400 [=======>......................] - ETA: 241s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1920/6400 [========>.....................] - ETA: 238s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1984/6400 [========>.....................] - ETA: 235s - loss: 2.3016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2048/6400 [========>.....................] - ETA: 231s - loss: 2.3018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2112/6400 [========>.....................] - ETA: 228s - loss: 2.3018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2176/6400 [=========>....................] - ETA: 225s - loss: 2.3019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2240/6400 [=========>....................] - ETA: 221s - loss: 2.3017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2304/6400 [=========>....................] - ETA: 218s - loss: 2.3017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2368/6400 [==========>...................] - ETA: 214s - loss: 2.3018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2432/6400 [==========>...................] - ETA: 211s - loss: 2.3019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2496/6400 [==========>...................] - ETA: 208s - loss: 2.3019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2560/6400 [===========>..................] - ETA: 204s - loss: 2.3019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2624/6400 [===========>..................] - ETA: 201s - loss: 2.3019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2688/6400 [===========>..................] - ETA: 198s - loss: 2.3021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2752/6400 [===========>..................] - ETA: 194s - loss: 2.3020"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2816/6400 [============>.................] - ETA: 191s - loss: 2.3019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2880/6400 [============>.................] - ETA: 187s - loss: 2.3018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2944/6400 [============>.................] - ETA: 184s - loss: 2.3016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3008/6400 [=============>................] - ETA: 181s - loss: 2.3015"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3072/6400 [=============>................] - ETA: 177s - loss: 2.3015"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3136/6400 [=============>................] - ETA: 174s - loss: 2.3016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3200/6400 [==============>...............] - ETA: 170s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3264/6400 [==============>...............] - ETA: 167s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3328/6400 [==============>...............] - ETA: 164s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3392/6400 [==============>...............] - ETA: 160s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3456/6400 [===============>..............] - ETA: 157s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3520/6400 [===============>..............] - ETA: 153s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3584/6400 [===============>..............] - ETA: 150s - loss: 2.3014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3648/6400 [================>.............] - ETA: 147s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3712/6400 [================>.............] - ETA: 143s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3776/6400 [================>.............] - ETA: 140s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3840/6400 [=================>............] - ETA: 136s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3904/6400 [=================>............] - ETA: 133s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3968/6400 [=================>............] - ETA: 129s - loss: 2.3011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4032/6400 [=================>............] - ETA: 126s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4096/6400 [==================>...........] - ETA: 123s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4160/6400 [==================>...........] - ETA: 119s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4224/6400 [==================>...........] - ETA: 116s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4288/6400 [===================>..........] - ETA: 112s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4352/6400 [===================>..........] - ETA: 109s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4416/6400 [===================>..........] - ETA: 106s - loss: 2.3007"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4480/6400 [====================>.........] - ETA: 102s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4544/6400 [====================>.........] - ETA: 99s - loss: 2.3009 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4608/6400 [====================>.........] - ETA: 97s - loss: 2.3008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4672/6400 [====================>.........] - ETA: 94s - loss: 2.3007"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4736/6400 [=====================>........] - ETA: 91s - loss: 2.3007"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4800/6400 [=====================>........] - ETA: 88s - loss: 2.3008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4864/6400 [=====================>........] - ETA: 85s - loss: 2.3007"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4928/6400 [======================>.......] - ETA: 81s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4992/6400 [======================>.......] - ETA: 78s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5056/6400 [======================>.......] - ETA: 75s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5120/6400 [=======================>......] - ETA: 71s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5184/6400 [=======================>......] - ETA: 68s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5248/6400 [=======================>......] - ETA: 64s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5312/6400 [=======================>......] - ETA: 61s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5376/6400 [========================>.....] - ETA: 57s - loss: 2.3011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5440/6400 [========================>.....] - ETA: 54s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5504/6400 [========================>.....] - ETA: 50s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5568/6400 [=========================>....] - ETA: 46s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5632/6400 [=========================>....] - ETA: 43s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5696/6400 [=========================>....] - ETA: 39s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5760/6400 [==========================>...] - ETA: 36s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5824/6400 [==========================>...] - ETA: 32s - loss: 2.3013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5888/6400 [==========================>...] - ETA: 28s - loss: 2.3012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5952/6400 [==========================>...] - ETA: 25s - loss: 2.3011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6016/6400 [===========================>..] - ETA: 21s - loss: 2.3011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6080/6400 [===========================>..] - ETA: 17s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6144/6400 [===========================>..] - ETA: 14s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6208/6400 [============================>.] - ETA: 10s - loss: 2.3009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6272/6400 [============================>.] - ETA: 7s - loss: 2.3009 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6336/6400 [============================>.] - ETA: 3s - loss: 2.3010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6400/6400 [==============================] - 359s - loss: 2.3010   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_set_error(model, n=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "98.74\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model._predict(test_set_x[:1]).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "(1, 10)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}